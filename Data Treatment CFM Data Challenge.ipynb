{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_data(filename, delimiter):\n",
    "    data = []\n",
    "    with open(filename, 'rb') as csvfile:\n",
    "        rows = csv.reader(csvfile, delimiter = delimiter)\n",
    "        for row in rows:\n",
    "            data.append(' '.join(row))\n",
    "    return data\n",
    "\n",
    "def treatment(data_list):\n",
    "    ## converting strings to floats\n",
    "    for i in range(1,len(data_list)): \n",
    "        data_list[i] = data_list[i].split()\n",
    "        data_list[i] = map(float, data_list[i])\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all data \n",
    "\n",
    "## Organising the data \n",
    "\n",
    "Two options possible: either do it in one big data frame or in atomized units. \n",
    "\n",
    "Actually keeping the two is a good idea since we can get a global feel of the data with the huge data frame and then more nuanced stuff using one data frame for every 8 entries. \n",
    "\n",
    "You also need fast read and write: do it via HDF. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('training_input.csv')\n",
    "test_data = pd.read_csv('testing_input.csv')\n",
    "target_data = pd.read_csv('challenge_output_data_training_file_prediction_of_trading_activity_within_the_order_book.csv',\n",
    "                         delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>  2</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>  3</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  4</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  5</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>  6</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>  7</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>  8</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>  9</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 10</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  TARGET\n",
       "0   1       1\n",
       "1   2       0\n",
       "2   3       1\n",
       "3   4       0\n",
       "4   5       0\n",
       "5   6       1\n",
       "6   7       1\n",
       "7   8       0\n",
       "8   9       1\n",
       "9  10       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import HDFStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf = HDFStore('challenge_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.put('training', training_data, format='table', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv\\Anaconda\\lib\\site-packages\\tables\\path.py:100: NaturalNameWarning: object name is not a valid Python identifier: 'ID;TARGET'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n",
      "C:\\Users\\Dhruv\\Anaconda\\lib\\site-packages\\tables\\path.py:100: NaturalNameWarning: object name is not a valid Python identifier: 'ID;TARGET_kind'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n",
      "C:\\Users\\Dhruv\\Anaconda\\lib\\site-packages\\tables\\path.py:100: NaturalNameWarning: object name is not a valid Python identifier: 'ID;TARGET_meta'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n",
      "C:\\Users\\Dhruv\\Anaconda\\lib\\site-packages\\tables\\path.py:100: NaturalNameWarning: object name is not a valid Python identifier: 'ID;TARGET_dtype'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    }
   ],
   "source": [
    "hdf.put('test', test_data, format='table', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(587214, 1)\n",
      "(4697712, 23)\n",
      "(4697720, 23)\n"
     ]
    }
   ],
   "source": [
    "print target_data.shape\n",
    "print training_data.shape\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = collect_data('training_input.csv' , delimiter=',')\n",
    "test_data = collect_data('testing_input.csv', delimiter=',')\n",
    "target_data = collect_data('challenge_output_data_training_file_prediction_of_trading_activity_within_the_order_book.csv',\n",
    "                           delimiter = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697713 4697721 587215\n"
     ]
    }
   ],
   "source": [
    "print len(train_data), len(test_data), len(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = treatment(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data  = treatment(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 -500 1443.0 1444.0 1442.0 1445.0 170 119 509 579 35 17 78 82 1.91590043224 1.76231471084 2.3281993832 2.45821894169 64.0 1.0 9.0 1.0 0.0'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = train_data[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -1000.0, 1443.0, 1444.0, 1442.0, 1445.0, 170.0, 119.0, 509.0, 579.0, 35.0, 17.0, 78.0, 82.0, 1.91590043224, 1.76231471084, 2.3281993832, 2.45821894169, 64.0, 1.0, 9.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test = map(float, test)\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags2 = tags2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'offset', 'bid_1', 'ask_1', 'bid_2', 'ask_2', 'bid_size_1', 'ask_size_1', 'bid_size_2', 'ask_size_2', 'bid_entry_1', 'ask_entry_1', 'bid_entry_2', 'ask_entry_2', 'bid_entropy_1', 'ask_entropy_1', 'bid_entropy_2', 'ask_entropy_2', 'bid_sqentry_1', 'ask_sqentry_1', 'bid_sqentry_2', 'ask_sqentry_2', 'nb_trade']\n"
     ]
    }
   ],
   "source": [
    "print tags2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1000 1443.0 1444.0 1442.0 1445.0 170 119 509 579 35 17 78 82 1.91590043224 1.76231471084 2.3281993832 2.45821894169 64.0 1.0 9.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print all_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1000 1443.0 1444.0 1442.0 1445.0 170 119 509 579 35 17 78 82 1.91590043224 1.76231471084 2.3281993832 2.45821894169 64.0 1.0 9.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "test = all_data[1]\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '-1000', '1443.0', '1444.0', '1442.0', '1445.0', '170', '119', '509', '579', '35', '17', '78', '82', '1.91590043224', '1.76231471084', '2.3281993832', '2.45821894169', '64.0', '1.0', '9.0', '1.0', '0.0']\n"
     ]
    }
   ],
   "source": [
    "test = test.split()\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -1000.0, 1443.0, 1444.0, 1442.0, 1445.0, 170.0, 119.0, 509.0, 579.0, 35.0, 17.0, 78.0, 82.0, 1.91590043224, 1.76231471084, 2.3281993832, 2.45821894169, 64.0, 1.0, 9.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "test = map(float, test)\n",
    "print test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Maybe splitting the files might work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import chain, islice\n",
    "def chunks(iterable,n):\n",
    "    iterable = iter(iterable)\n",
    "    while True:\n",
    "        yield chain([next(iterable)],islice(iterable, n-1))\n",
    "size = 30*10**6\n",
    "test_file = 'training_input.csv'\n",
    "with open(test_file) as bigfile:\n",
    "    for i, lines in enumerate(chunks(bigfile,size)):\n",
    "        file_split = '{}.{}'.format(test_file,i)\n",
    "        with open(file_split,'w') as f:\n",
    "            f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
