{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "18963e32-a5b6-42db-a16f-3aa74794ed66"
    }
   },
   "source": [
    "# Module d'importation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importe et crée les groupes associés, plus deux groupes de base pour savoir ce qu'on manipule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "name": "groupby",
    "nbpresent": {
     "id": "5bd54ebb-ec0d-45a8-b1a3-9f534f9ab2eb"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "    \n",
    "training_data = pd.read_csv('Training_XS_300.csv', delimiter=';')\n",
    "training_group=training_data.loc[:,['ID', 'bid_1', 'bid_size_1','nb_trade']].groupby('ID')\n",
    "\n",
    "target_data = pd.read_csv('Target_data.csv', delimiter=';', nrows=len(training_group))\n",
    "\n",
    "training_group1=training_group.get_group(1)\n",
    "target_group1=target_group.get_group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d6186486-a517-4365-b6ad-477384d159c4"
    }
   },
   "source": [
    "# Fonctions type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour itérer sur les groupes, il est possible d'utiliser des for-loops, a priori il faut préférer des variantes de map, en particulier apply(), le problème c'est qu'apply renvoie un DataFrame qui sera donc une copie de la data d'origine. Il n'est pas possible de modifier en place le DataFrame qui a généré le groupe. C'est bien adapté pour des sum() ou std() (catégorie agg) moins pour ajouter une colonne (catégorie transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-modification, ce type de fonction s'itère bien avec apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_product(vect, ind1, ind2):\n",
    "    ## adds a new colum to vect from the product of ind1 and ind2\n",
    "    vect[str(ind1)+\"_prod_\"+str(ind2)]=vect[str(ind2)]*vect[str(ind2)]\n",
    "    return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf_training_data=training_group.apply(lambda x: add_product(x, 'bid_1', 'bid_size_1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint-modification, c'est là que ça coince. Il est facile d'appliquer une fonction conjointe sur deux data frame, pas pour deux groupes. Un groupe ne sert que comme objet sur lequel faire des apply ou des opérations partielles. Il n'est pas un objet manipulable en soi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_variation_counter_group(group1, df2, indlist):\n",
    "    ## adds a new colum to df2 from the variation counter for ind in indlist in group1\n",
    "    for name, df1 in group1:\n",
    "        for ind in indlist:\n",
    "            df2.ix[name,str(ind)+\"_varcount\"]=df1[str(ind)].diff().astype(bool).sum()-1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pratique il faut faire toutes les opérations en un coup. On peut aussi se passer du df2 ci-dessus et créer directement la table de valeurs moyennes ou statistiques, puis lui ajouter la colonne TARGET si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def g(x, *arg):\n",
    "    add_product(x, 'ask_1', 'ask_size_1')\n",
    "    add_product(x, 'bid_1', 'bid_size_1')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf_training_data=training_group.apply(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je ne pense pas que manipuler deux groupes conjointement soit une bonne idée. Il faudrait faire des opérations intra-groupe puis des actions inter-DataFrame. Il y a un problème d'indexation chez nous parce que nous avons laissé celle naturelle d'Excel qui compte les lignes. Celle-ci est inutile, je propose de la remplacer par une indexation hiérarchique à deux niveaux 'ID' puis 'offset' dont les valeurs d'index seraient des float. Les autres colonnes resteraient telles quelles avec possibilité de faire une séparation \"old/new\" si on crée des variables.\n",
    "\n",
    "L'autre problème vient de scikit, il attend une matrice nb_points x nb_features. Dans tous les cas il faudra déplier nos dataframe par reshape ou unstack (si hiérarchique).\n",
    "\n",
    "Il peut être intéressant de faire les réindexations sur place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transf_training_data.set_index(['ID','offset'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique un SVC (SVM pour classes avec noyau gaussien ici) très facilement et on récupère l'accuracy. Le gros problème est que cette méthode s'adapte mal à l'échelle. D'où grosse réflexion sur les méthodes à employer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76530612244897955"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbt=training_data['nb_trade']\n",
    "nbt=np.reshape(nbt,(-1,8))\n",
    "targ=target_data['TARGET']\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(nbt, targ)  \n",
    "clf.score(nbt, targ)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
